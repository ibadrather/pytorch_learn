{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Head Fine-Tuning\n",
    "\n",
    "Multi-head fine-tuning refers to the practice of fine-tuning a pre-trained model for multiple tasks simultaneously. This is often done by adding multiple \"heads\" to a shared \"base\" model. Each head is responsible for a specific task. The idea is that the shared layers learn general features that are useful for all tasks, while each head specializes in its own task.\n",
    "\n",
    "For example, in a natural language processing scenario, you might have one head for sentiment analysis and another for named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt-get install libopenmpi-dev\n",
    "# !sudo apt install nvidia-cuda-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch==1.12.1 transformers deepspeed mpi4py --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "import deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        # Sentiment analysis head (binary classification)\n",
    "        self.sentiment_head = nn.Linear(768, 1)\n",
    "        \n",
    "        # Named entity recognition head (let's assume 10 classes)\n",
    "        self.ner_head = nn.Linear(768, 10)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        \n",
    "        # For sentiment analysis, we'll just use the [CLS] token representation\n",
    "        cls_token = last_hidden_state[:, 0, :]\n",
    "        sentiment_output = self.sentiment_head(cls_token)\n",
    "        \n",
    "        # For NER, we'll use the representation for each token\n",
    "        ner_output = self.ner_head(last_hidden_state)\n",
    "        \n",
    "        return sentiment_output, ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = MultiHeadModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Initialize DeepSpeed\n",
    "model, optimizer, _, _ = deepspeed.initialize(optimizer=optimizer,model=model,config='ds_config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "num_samples = 10000\n",
    "max_length = 50\n",
    "\n",
    "positive_texts = [\"I absolutely love this product!\", \n",
    "                  \"This is amazing, I'm so happy with it.\", \n",
    "                  \"Fantastic experience, would recommend to anyone.\", \n",
    "                  \"Great job, keep up the good work!\", \n",
    "                  \"Excellent service, couldn't be happier.\"]\n",
    "\n",
    "negative_texts = [\"I really hate this, it's awful.\", \n",
    "                  \"This is terrible, would not recommend to anyone.\", \n",
    "                  \"Awful experience, I'm so disappointed.\", \n",
    "                  \"Bad job, this needs a lot of improvement.\", \n",
    "                  \"Poor service, not happy at all.\"]\n",
    "\n",
    "texts = []\n",
    "sentiments = []\n",
    "\n",
    "persons = [\"John\", \"Emily\", \"Michael\", \"Sarah\"]\n",
    "organizations = [\"Google\", \"Microsoft\", \"Apple\"]\n",
    "locations = [\"New York\", \"San Francisco\", \"London\"]\n",
    "ner_sentences = [\n",
    "    \"[PERSON] works at [ORG].\",\n",
    "    \"[PERSON] lives in [LOC].\",\n",
    "    \"[ORG] is located in [LOC].\"\n",
    "]\n",
    "ners = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Sentiment\n",
    "    if random.choice([True, False]):\n",
    "        texts.append(random.choice(positive_texts))\n",
    "        sentiments.append(1)\n",
    "    else:\n",
    "        texts.append(random.choice(negative_texts))\n",
    "        sentiments.append(0)\n",
    "\n",
    "    # NER\n",
    "    ner_sentence = random.choice(ner_sentences)\n",
    "    ner_sentence = ner_sentence.replace(\"[PERSON]\", random.choice(persons))\n",
    "    ner_sentence = ner_sentence.replace(\"[ORG]\", random.choice(organizations))\n",
    "    ner_sentence = ner_sentence.replace(\"[LOC]\", random.choice(locations))\n",
    "    ner_label_sequence = [0 if word not in persons + organizations + locations else persons.index(word) + 1 \n",
    "                          if word in persons else organizations.index(word) + 5 \n",
    "                          if word in organizations \n",
    "                          else locations.index(word) + 8 \n",
    "                          for word in ner_sentence.split()\n",
    "                          ]\n",
    "    \n",
    "    ner_label_sequence += [0] * (max_length - len(ner_label_sequence))  # Padding\n",
    "    ners.append(ner_label_sequence[:max_length])\n",
    "\n",
    "sentiments = torch.tensor(sentiments, dtype=torch.float32).view(-1, 1)\n",
    "ners = torch.tensor(ners, dtype=torch.long)\n",
    "\n",
    "# Tokenize the texts\n",
    "encoding = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_mask, sentiments, ners)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, sentiment_labels, ner_labels = batch\n",
    "\n",
    "        input_ids = input_ids.to(model.device)\n",
    "        attention_mask = attention_mask.to(model.device)\n",
    "        sentiment_labels = sentiment_labels.to(model.device)\n",
    "        ner_labels = ner_labels.to(model.device)\n",
    "\n",
    "        sentiment_output, ner_output = model(input_ids, attention_mask)\n",
    "        \n",
    "        sentiment_loss = F.binary_cross_entropy_with_logits(sentiment_output, sentiment_labels)\n",
    "        ner_loss = F.cross_entropy(ner_output.view(-1, 10), ner_labels.view(-1))\n",
    "        loss = sentiment_loss + ner_loss\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\"I love this max!\", \"This is terrible anna!\"]\n",
    "encoding = tokenizer(test_texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "input_ids = encoding['input_ids'].to(model.device)\n",
    "attention_mask = encoding['attention_mask'].to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sentiment_output, ner_output = model(input_ids, attention_mask)\n",
    "    sentiment_output = torch.sigmoid(sentiment_output)\n",
    "    ner_output = torch.argmax(ner_output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the sentiment output\n",
    "sentiment_output_np = sentiment_output.cpu().numpy()\n",
    "sentiment_labels = [\"Positive\" if score > 0.5 else \"Negative\" for score in sentiment_output_np]\n",
    "\n",
    "# Interpret the NER output\n",
    "ner_output_np = ner_output.cpu().numpy()\n",
    "ner_classes = ['O', 'PERSON', 'ORG', 'LOC', 'DATE', 'TIME', 'MONEY', 'PERCENT', 'FAC', 'GPE']\n",
    "ner_labels = [[ner_classes[label] for label in sequence] for sequence in ner_output_np]\n",
    "\n",
    "for i, (sentiment, ner) in enumerate(zip(sentiment_labels, ner_labels)):\n",
    "    print(f\"Sentence {i+1}:\")\n",
    "    print(f\"  Sentiment: {sentiment}\")\n",
    "    print(f\"  NER Labels: {ner}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
